{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li> </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version', tf.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (23330, 28, 140)\n",
      "Y 'shape' (1, 23330)\n",
      "Y first example shape (1, 10)\n",
      "Y last example shape (5, 10)\n"
     ]
    }
   ],
   "source": [
    "synth_data = loadmat('./fabricated_mnist_data/data_and_labels.mat')\n",
    "all_x = synth_data['data']\n",
    "all_y = synth_data['labels']\n",
    "print(\"X shape\", all_x.shape)\n",
    "print(\"Y 'shape'\", all_y.shape)\n",
    "print(\"Y first example shape\", all_y[0, 0].shape)\n",
    "print(\"Y last example shape\", all_y[0, -1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape y by padding < 5 length labels, and getting the length of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],\n",
       "       [ 10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y = all_y.reshape(-1)\n",
    "all_y_lens = np.array([len(y_ex) for y_ex in all_y])\n",
    "def pad(y_ex):\n",
    "    toreturn = np.zeros((5, 10))\n",
    "    toreturn[:len(y_ex), :] = y_ex\n",
    "    return toreturn\n",
    "pad(np.arange(10*2).reshape(2, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23330, 5, 10)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y = np.array([pad(y_ex) for y_ex in all_y])\n",
    "all_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(num):\n",
    "    num = np.ravel(num).astype(int)\n",
    "    toreturn = np.zeros(shape=(len(num), 5), dtype=np.int16)\n",
    "    for i, dig in enumerate(num):\n",
    "        toreturn[i, dig-1] = 1\n",
    "    return toreturn    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_y_lens = one_hot(all_y_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "idx = np.arange(len(all_x))\n",
    "np.random.shuffle(idx)\n",
    "temp = len(all_x)//5\n",
    "\n",
    "train_idx = idx[:(temp*3)]\n",
    "valid_idx = idx[(temp*3):(temp*4)]\n",
    "test_idx = idx[(temp*4):]\n",
    "\n",
    "train_x = all_x[train_idx].reshape(-1, 28, 140, 1)\n",
    "train_y = all_y[train_idx]\n",
    "train_ylen = all_y_lens[train_idx]\n",
    "\n",
    "valid_x = all_x[valid_idx].reshape(-1, 28, 140, 1)\n",
    "valid_y = all_y[valid_idx]\n",
    "valid_ylen = all_y_lens[valid_idx]\n",
    "\n",
    "test_x = all_x[test_idx].reshape(-1, 28, 140, 1)\n",
    "test_y = all_y[test_idx]\n",
    "test_ylen = all_y_lens[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_xe(output, target):\n",
    "    \"\"\"Compute the average cross entropy of sequences up to the lengths of the targets.\n",
    "    \n",
    "    This assumes a target is of shape [N, L, K], where N is the number of examples, L is the maximum \n",
    "    sequence length, and K is the number of classes. Additionally, target should be zero-padded to\n",
    "    arrive at the max sequence length for all sequences\n",
    "    \n",
    "    Borrowed from https://danijar.com/variable-sequence-lengths-in-tensorflow/.\n",
    "    \"\"\"\n",
    "    cross_entropy = target * tf.log(output)\n",
    "    cross_entropy = -tf.reduce_sum(cross_entropy, reduction_indices=2)\n",
    "    mask = tf.sign(tf.reduce_max(tf.abs(target), reduction_indices=2))\n",
    "    cross_entropy *= mask\n",
    "    \n",
    "    cross_entropy = tf.reduce_sum(cross_entropy, reduction_indices=1)\n",
    "    cross_entropy /= tf.reduce_sum(mask, reduction_indices=1)\n",
    "    return tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pred(len_proba, dig_proba):\n",
    "    length = np.argmax(len_proba, axis=-1)\n",
    "    digits = np.argmax(dig_proba, axis=-1)\n",
    "    \n",
    "    return [''.join([str(x) for x in dig[:ilen+1]]) for ilen, dig in zip(length, digits)]\n",
    "lens = [\n",
    "    [0, 1]+[0]*3\n",
    "]\n",
    "digs = [\n",
    "    [\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "    ]\n",
    "]\n",
    "get_pred(lens, digs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = [\n",
    "    [0, 1]+[0]*3,\n",
    "    [0, 0, 0, 1]+[0]\n",
    "]\n",
    "digs = [\n",
    "    [\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "    ],\n",
    "    [\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plens = [\n",
    "    [0, 1]+[0]*3,\n",
    "    [0, 0, 1]+[0]*2\n",
    "]\n",
    "pdigs = [\n",
    "    [\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "    ],\n",
    "    [\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "        [0, 1]+[0]*8,\n",
    "        [0, 0.2, 0.8] + [0]*7,\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '1212']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(lens, digs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '1212']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(lens, digs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y_true, y_len_true, y_pred, y_len_pred):\n",
    "    actual = np.array(get_pred(y_len_true, y_true))\n",
    "    pred = np.array(get_pred(y_len_pred, y_pred))\n",
    "    return np.mean(actual == pred)\n",
    "accuracy(digs, lens, pdigs, plens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "momentum = 0.7\n",
    "len_balance = 0.6  # give the sequence length loss len_balance weight and the sequence digits loss (1-len_balance) weight \n",
    "simplest_graph =  tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with simplest_graph.as_default(): \n",
    "    tf_x = tf.placeholder(tf.float32, (None, all_x.shape[1], all_x.shape[2], 1))\n",
    "    tf_y = tf.placeholder(tf.float32, (None, all_y.shape[1], all_y.shape[2]))\n",
    "    tf_ylen = tf.placeholder(tf.int32, (None, 5))\n",
    "    \n",
    "    # (N, 28, 140, 1)\n",
    "    conv1_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 1, 3], stddev=0.1, seed=54), name=\"conv1_w\")\n",
    "    conv1_b = tf.Variable(tf.zeros(shape=[3]), name=\"conv1_b\")\n",
    "    \n",
    "    # (N, 28, 140, 3)\n",
    "    \n",
    "    # (N, 10, 47, 3) -> (N, 1410)\n",
    "    dens3_w = tf.Variable(tf.truncated_normal(shape=[1410, 200], stddev=0.1, seed=65), name=\"dens3_w\")\n",
    "    dens3_b = tf.Variable(tf.zeros(shape=[200]), name=\"dens3_b\")\n",
    "    \n",
    "    # (N, 200)\n",
    "    len_w = tf.Variable(tf.truncated_normal(shape=[200, 5], stddev=0.1, seed=76), name=\"len_w\")\n",
    "    len_b = tf.Variable(tf.zeros(shape=[5]), name=\"len_b\")\n",
    "    \n",
    "    # (N, 200)\n",
    "    dig_w = tf.Variable(tf.truncated_normal(shape=[200, 5*10], stddev=0.1, seed=87), name=\"dig_w\")\n",
    "    dig_b = tf.Variable(tf.zeros(shape=[5*10]), name=\"dig_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    o1 = tf.nn.relu(tf.nn.conv2d(x, conv1_w, [1, 1, 1, 1], 'SAME') + conv1_b)\n",
    "    o2 = tf.nn.max_pool(o1, [1, 3, 3, 1], [1, 3, 3, 1], 'SAME')\n",
    "    o2resh = tf.reshape(o2, [-1, 1410])\n",
    "    o3 = tf.nn.relu(tf.matmul(o2resh, dens3_w) + dens3_b)\n",
    "    return o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with simplest_graph.as_default():\n",
    "    \n",
    "    hrep = model(tf_x)\n",
    "    tf_lenlogit = tf.matmul(hrep, len_w) + len_b\n",
    "    tf_lenproba = tf.nn.softmax(tf_lenlogit)\n",
    "    tf_diglogit = tf.reshape(tf.matmul(hrep, dig_w) + dig_b, [-1, 5, 10])\n",
    "    tf_digproba = tf.nn.softmax(tf_diglogit, dim=-1)\n",
    "    \n",
    "    tf_len_loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf_ylen, logits=tf_lenlogit)\n",
    "    tf_dig_loss = masked_xe(tf_digproba, tf_y)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    updater = optimizer.minimize(tf_len_loss*len_balance + tf_dig_loss*(1-len_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 20\n",
    "steps_per_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Validation accuracy 1.650%\n",
      "Mean batch len loss nan\n",
      "Valid len loss nan\n",
      "Mean batch dig loss nan\n",
      "Valid dig loss nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-296-dbf880ab2139>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mbatch_ylen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ylen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         _,  batch_len_loss, batch_dig_loss = session.run([updater, tf_len_loss, tf_dig_loss], \n\u001b[1;32m---> 18\u001b[1;33m                                                          feed_dict={tf_x: batch_x, tf_y: batch_y, tf_ylen: batch_ylen})\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mep_len_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_len_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mep_dig_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dig_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession(graph=simplest_graph)\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "np.random.seed(123456)\n",
    "for ep in range(n_epochs):\n",
    "    idx = np.arange(len(train_x))\n",
    "    np.random.shuffle(idx) # shuffling the data each epoch\n",
    "    train_x = train_x[idx]\n",
    "    train_y = train_y[idx]\n",
    "    train_ylen = train_ylen[idx]\n",
    "    ep_len_losses = []\n",
    "    ep_dig_losses = []\n",
    "    for batch_idx in range(min(len(train_x)//batch_size, steps_per_epoch)):\n",
    "        batch_x = train_x[batch_size*batch_idx:(batch_size*(batch_idx+1))].reshape(-1, 28, 140, 1)\n",
    "        batch_y = train_y[batch_size*batch_idx:(batch_size*(batch_idx+1))]\n",
    "        batch_ylen = train_ylen[batch_size*batch_idx:(batch_size*(batch_idx+1))]\n",
    "        _,  batch_len_loss, batch_dig_loss = session.run([updater, tf_len_loss, tf_dig_loss], \n",
    "                                                         feed_dict={tf_x: batch_x, tf_y: batch_y, tf_ylen: batch_ylen})\n",
    "        ep_len_losses.append(np.mean(batch_len_loss))\n",
    "        ep_dig_losses.append(np.mean(batch_dig_loss))\n",
    "        \n",
    "    v_len_loss, v_dig_loss, v_len_proba, v_dig_proba = session.run([tf_len_loss, tf_dig_loss, tf_lenproba, tf_digproba], \n",
    "                                                                {tf_x: valid_x, tf_y: valid_y, tf_ylen: valid_ylen})\n",
    "#     print(np.array(ep_len_losses))\n",
    "#     print(np.mean(v_len_loss))\n",
    "    print(\"Epoch {}\".format(ep))\n",
    "    print(\"Validation accuracy {:<2.3%}\".format(accuracy(valid_y, valid_ylen, v_dig_proba, v_len_proba)))\n",
    "          \n",
    "    print(\"Mean batch len loss {:<2.3f}\".format(np.mean(ep_len_losses)))\n",
    "    print(\"Valid len loss {:<2.3f}\".format(np.mean(v_len_loss)))\n",
    "    \n",
    "    print(\"Mean batch dig loss {:<2.3f}\".format(np.mean(ep_dig_losses)))\n",
    "    print(\"Valid dig loss {:<2.3f}\".format(np.mean(v_dig_loss)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with simplest_graph.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32, (None, all_x.shape[1], all_x.shape[2]))\n",
    "    tf_y = tf.placeholder(tf.float32, (None, all_y.shape[1], all_y.shape[2]))\n",
    "    tf_ylen = tf.placeholder(tf.int32, (None, 5))\n",
    "    \n",
    "#     weights\n",
    "    def model(x):\n",
    "        o1 = tf.nn.relu(tf.nn.conv2d(x, conv1_w, [1, 1, 1, 1], 'same') + conv1_b)\n",
    "        o2 = tf.nn.max_pool(o1, [1, 3, 3, 1], [1, 1, 1, 1], 'same')\n",
    "        o2resh = tf.reshape(o2, [x.get_shape()[0], -1])\n",
    "        o3 = tf.nn.relu(tf.matmul(o2resh, dens3_w) + dens3_b)\n",
    "        return o3\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#     tf.train.AdamOptimizer.minimize()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 10))\n",
    "w = tf.Variable(np.arange(10).reshape((10, 1)), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros(1), dtype=tf.float32)\n",
    "y = tf.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  285.]\n",
      " [  735.]\n",
      " [ 1185.]\n",
      " [ 1635.]\n",
      " [ 2085.]\n",
      " [ 2535.]\n",
      " [ 2985.]\n",
      " [ 3435.]\n",
      " [ 3885.]\n",
      " [ 4335.]\n",
      " [ 4785.]\n",
      " [ 5235.]\n",
      " [ 5685.]\n",
      " [ 6135.]\n",
      " [ 6585.]\n",
      " [ 7035.]\n",
      " [ 7485.]\n",
      " [ 7935.]\n",
      " [ 8385.]\n",
      " [ 8835.]]\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "print(y.eval({x: np.arange(10*20).reshape(-1, 10)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
